package main

import (
	"context"
	"encoding/xml"
	"fmt"
	"os"
	"time"

	"github.com/ruslano69/tdtp-framework/pkg/adapters"
	"github.com/ruslano69/tdtp-framework/pkg/core/packet"
	"github.com/ruslano69/tdtp-framework/pkg/core/schema"

	_ "github.com/ruslano69/tdtp-framework/pkg/adapters/sqlite"
)

func main() {
	ctx := context.Background()

	fmt.Println("=== TDTP Pagination Demo (2MB packets) ===")
	fmt.Println()

	// 1. –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –ë–î —Å 100,000 –∑–∞–ø–∏—Å–µ–π
	var dbPath string
	var targetTable string

	if len(os.Args) > 1 {
		dbPath = os.Args[1]
		if len(os.Args) > 2 {
			targetTable = os.Args[2]
		}
	} else {
		fmt.Println("Usage: go run main.go <path-to-database> [table-name]")
		fmt.Println("Example: go run main.go testdata/large.db users")
		fmt.Println("         go run main.go testdata/large.db")
		fmt.Println("\nCreating demo database with 10,000 records...")
		dbPath = "pagination_demo.db"
		defer os.Remove(dbPath)

		if err := createDemoDatabase(ctx, dbPath); err != nil {
			panic(err)
		}
	}

	cfg := adapters.Config{
		Type: "sqlite",
		DSN:  dbPath,
	}

	adapter, err := adapters.New(ctx, cfg)
	if err != nil {
		panic(err)
	}
	defer adapter.Close(ctx)

	// 2. –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ç–∞–±–ª–∏—Ü
	fmt.Println("üìã Available tables:")
	tables, err := adapter.GetTableNames(ctx)
	if err != nil {
		panic(err)
	}

	if len(tables) == 0 {
		fmt.Println("   No tables found in database")
		return
	}

	for _, table := range tables {
		fmt.Printf("   - %s\n", table)
	}

	// –í—ã–±–∏—Ä–∞–µ–º —Ç–∞–±–ª–∏—Ü—É
	var tableName string
	if targetTable != "" {
		// –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —É–∫–∞–∑–∞–Ω–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
		found := false
		for _, table := range tables {
			if table == targetTable {
				found = true
				tableName = targetTable
				break
			}
		}
		if !found {
			fmt.Printf("\n‚ùå Table '%s' not found in database\n", targetTable)
			fmt.Println("Available tables listed above")
			return
		}
	} else {
		// –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—É—é —Ç–∞–±–ª–∏—Ü—É
		tableName = tables[0]
	}

	fmt.Printf("\nüîç Using table: %s\n", tableName)

	// 3. –ü–æ–ª—É—á–∞–µ–º —Å—Ö–µ–º—É —Ç–∞–±–ª–∏—Ü—ã
	schemaObj, err := adapter.GetTableSchema(ctx, tableName)
	if err != nil {
		panic(err)
	}

	fmt.Printf("   Schema: %d fields\n", len(schemaObj.Fields))
	for i, field := range schemaObj.Fields {
		primaryKey := ""
		if field.Key {
			primaryKey = " [PK]"
		}
		fmt.Printf("     %d. %s (%s)%s\n", i+1, field.Name, field.Type, primaryKey)
	}

	// 4. –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ç–∞–±–ª–∏—Ü—É —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π
	fmt.Println("\nüì§ Exporting table with pagination (2MB packets)...")

	startTime := time.Now()
	packets, err := adapter.ExportTable(ctx, tableName)
	if err != nil {
		panic(err)
	}
	exportDuration := time.Since(startTime)

	fmt.Printf("   ‚úÖ Export completed in %v\n\n", exportDuration)

	// 5. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–∞–∫–µ—Ç—ã –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ XML
	fmt.Printf("üìä Pagination Results:\n")
	fmt.Printf("   Total packets: %d\n\n", len(packets))

	// –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è XML —Ñ–∞–π–ª–æ–≤
	outputDir := "pagination_output"
	os.RemoveAll(outputDir) // –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ —Ñ–∞–π–ª—ã
	err = os.MkdirAll(outputDir, 0755)
	if err != nil {
		panic(err)
	}

	totalRows := 0
	totalSize := 0
	xmlFiles := []string{}

	for i, pkt := range packets {
		// –°–µ—Ä–∏–∞–ª–∏–∑—É–µ–º –ø–∞–∫–µ—Ç –≤ XML –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ —Ä–∞–∑–º–µ—Ä–∞
		xmlData, err := xml.MarshalIndent(pkt, "", "  ")
		if err != nil {
			panic(err)
		}

		packetSize := len(xmlData)
		totalSize += packetSize
		rowCount := len(pkt.Data.Rows)
		totalRows += rowCount

		// –°–æ—Ö—Ä–∞–Ω—è–µ–º XML —Ñ–∞–π–ª
		xmlFilename := fmt.Sprintf("%s/%s_part_%02d_of_%02d.xml", outputDir, tableName, i+1, len(packets))
		xmlContent := []byte("<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n" + string(xmlData))
		err = os.WriteFile(xmlFilename, xmlContent, 0644)
		if err != nil {
			panic(err)
		}
		xmlFiles = append(xmlFiles, xmlFilename)

		fmt.Printf("   Packet #%d:\n", i+1)
		fmt.Printf("     - Rows: %d\n", rowCount)
		fmt.Printf("     - Size: %.2f KB (%.2f MB)\n", float64(packetSize)/1024, float64(packetSize)/1024/1024)
		fmt.Printf("     - Part number: %d\n", pkt.Header.PartNumber)
		fmt.Printf("     - Total parts: %d\n", pkt.Header.TotalParts)
		fmt.Printf("     - XML file: %s\n", xmlFilename)

		if len(pkt.Data.Rows) > 0 {
			// –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É –∫–∞–∫ –ø—Ä–∏–º–µ—Ä
			fmt.Printf("     - First row sample: %s...\n", truncate(pkt.Data.Rows[0].Value, 60))
		}
		fmt.Println()
	}

	fmt.Printf("üìà Summary:\n")
	fmt.Printf("   Total rows exported: %d\n", totalRows)
	fmt.Printf("   Total data size: %.2f MB\n", float64(totalSize)/1024/1024)
	fmt.Printf("   Average packet size: %.2f MB\n", float64(totalSize)/float64(len(packets))/1024/1024)
	fmt.Printf("   Average rows per packet: %d\n", totalRows/len(packets))
	fmt.Printf("   Export speed: %d rows/sec\n\n", int(float64(totalRows)/exportDuration.Seconds()))

	// 6. –¢–µ—Å—Ç–∏—Ä—É–µ–º —ç–∫—Å–ø–æ—Ä—Ç —Å —Ñ–∏–ª—å—Ç—Ä–æ–º –∏ –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π
	if len(schemaObj.Fields) > 0 {
		fmt.Println("üîç Testing export with filter + pagination...")

		// –ü—Ä–æ—Å—Ç–æ–π —Ñ–∏–ª—å—Ç—Ä –ø–æ –ø–µ—Ä–≤–æ–º—É –ø–æ–ª—é
		firstField := schemaObj.Fields[0].Name
		query := packet.Query{
			Language: "TDTQL",
			Filters: &packet.Filters{
				And: &packet.LogicalGroup{
					Filters: []packet.Filter{
						{Field: firstField, Operator: "gte", Value: "1000"},
					},
				},
			},
		}

		startTime = time.Now()
		filteredPackets, err := adapter.ExportTableWithQuery(ctx, tableName, &query, "PaginationDemo", "FilterTest")
		if err != nil {
			panic(err)
		}
		filterDuration := time.Since(startTime)

		filteredRows := 0
		for _, pkt := range filteredPackets {
			filteredRows += len(pkt.Data.Rows)
		}

		fmt.Printf("   ‚úÖ Filtered export completed in %v\n", filterDuration)
		fmt.Printf("   Filtered packets: %d\n", len(filteredPackets))
		fmt.Printf("   Filtered rows: %d (%.1f%% of total)\n\n",
			filteredRows, float64(filteredRows)*100/float64(totalRows))

		// –ü—Ä–æ–≤–µ—Ä—è–µ–º QueryContext
		if len(filteredPackets) > 0 && filteredPackets[0].QueryContext != nil {
			qc := filteredPackets[0].QueryContext
			fmt.Println("üìä Query Context:")
			fmt.Printf("   - Language: %s\n", qc.OriginalQuery.Language)
			fmt.Printf("   - Records returned: %d\n", qc.ExecutionResults.RecordsReturned)
			fmt.Printf("   - Total in table: %d\n", qc.ExecutionResults.TotalRecordsInTable)
			fmt.Printf("   - More data available: %v\n", qc.ExecutionResults.MoreDataAvailable)
			if qc.ExecutionResults.MoreDataAvailable {
				fmt.Printf("   - Next offset: %d\n", qc.ExecutionResults.NextOffset)
			}
		}
	}

	fmt.Println("\n‚úÖ Pagination demo completed!")
	fmt.Printf("\nüìÅ XML Files saved to: %s/\n", outputDir)
	fmt.Printf("   Total files: %d\n", len(xmlFiles))
	for i, file := range xmlFiles {
		stat, _ := os.Stat(file)
		fmt.Printf("   [%02d] %s (%.2f KB)\n", i+1, file, float64(stat.Size())/1024)
	}

	fmt.Println("\nüí° Tips:")
	fmt.Println("   - MSMQ limit: 4 MB Binary ‚Üí ~1.9 MB XML (with headers overhead)")
	fmt.Println("   - Packets are split automatically based on content size")
	fmt.Println("   - Each packet preserves schema and metadata")
	fmt.Println("   - Multi-packet transfers can be imported atomically")
	fmt.Printf("   - You can inspect XML files in: %s/\n", outputDir)
}

// createDemoDatabase —Å–æ–∑–¥–∞–µ—Ç –¥–µ–º–æ –±–∞–∑—É —Å 10,000 –∑–∞–ø–∏—Å–µ–π
func createDemoDatabase(ctx context.Context, dbPath string) error {
	fmt.Println("   Creating demo table...")

	cfg := adapters.Config{
		Type: "sqlite",
		DSN:  dbPath,
	}

	adapter, err := adapters.New(ctx, cfg)
	if err != nil {
		return err
	}
	defer adapter.Close(ctx)

	// –°–æ–∑–¥–∞–µ–º —Å—Ö–µ–º—É
	builder := schema.NewBuilder()
	schemaObj := builder.
		AddInteger("id", true).
		AddText("name", 100).
		AddText("email", 100).
		AddText("address", 200).
		AddText("city", 50).
		AddText("country", 50).
		AddInteger("age", false).
		AddReal("balance").
		AddText("description", 500).
		Build()

	// –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
	const recordCount = 10000
	batchSize := 1000

	fmt.Printf("   Generating %d records...\n", recordCount)

	for batch := 0; batch < recordCount/batchSize; batch++ {
		rows := make([]packet.Row, batchSize)

		for i := 0; i < batchSize; i++ {
			id := batch*batchSize + i + 1
			rows[i] = packet.Row{
				Value: fmt.Sprintf("%d|User_%d|user_%d@example.com|Address line %d, Building %d|City_%d|Country_%d|%d|%.2f|This is a longer description field to increase row size. Record ID: %d. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.",
					id, id, id, id, id%100, id%50, id%200, 18+(id%50), float64(id)*123.45, id),
			}
		}

		testPacket := packet.NewDataPacket(packet.TypeReference, "demo_users")
		testPacket.Schema = schemaObj
		testPacket.Data = packet.Data{Rows: rows}

		if err := adapter.ImportPacket(ctx, testPacket, adapters.StrategyReplace); err != nil {
			return fmt.Errorf("failed to import batch %d: %w", batch, err)
		}

		fmt.Printf("   Progress: %d/%d records\r", (batch+1)*batchSize, recordCount)
	}

	fmt.Printf("\n   ‚úÖ Created demo table 'demo_users' with %d records\n\n", recordCount)
	return nil
}

func truncate(s string, maxLen int) string {
	if len(s) <= maxLen {
		return s
	}
	return s[:maxLen] + "..."
}
